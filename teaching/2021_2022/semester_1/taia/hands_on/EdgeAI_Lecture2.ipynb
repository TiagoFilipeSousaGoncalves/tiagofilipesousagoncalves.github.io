{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EdgeAI_Lecture2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNX3tm4cAdyj"
      },
      "source": [
        "# Edge AI - Lecture 2 (Hands-on)\n",
        "# TAIA - Advanced Topics on Artificial Intelligence\n",
        "# Tiago Filipe Sousa Gon√ßalves\n",
        "# tiago.f.goncalves@inesctec.pt | tiagofs@fe.up.pt\n",
        "# Leonardo Gomes Capozzi\n",
        "# leonardo.g.capozzi@inesctec.pt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcFfIgXbBGbb"
      },
      "source": [
        "# Contents\n",
        "\n",
        "\n",
        "## 1.   Spiking Neural Networks in [BindsNET](https://github.com/BindsNET/bindsnet)\n",
        "\n",
        "\n",
        "![imagem_2021-10-28_220112.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPeAiaYEBVWb"
      },
      "source": [
        "# Spiking Neural Networks in BindsNET\n",
        "Official GitHub repository:\n",
        "\n",
        "[https://github.com/BindsNET/bindsnet](https://github.com/BindsNET/bindsnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVqdIQZRKPqO"
      },
      "source": [
        "## Setup\n",
        "Let's start with the setup of our development environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWHS0xq3_Zzv"
      },
      "source": [
        "# Install libraries\n",
        "!pip install git+https://github.com/BindsNET/bindsnet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKw2jYkaywpw"
      },
      "source": [
        "Let's import the necessary libraries to run this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZckCvXhKdR7"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from time import time as t\n",
        "import _pickle as cPickle\n",
        "\n",
        "# PyTorch Imports\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# BindsNET Import\n",
        "from bindsnet.datasets import MNIST\n",
        "from bindsnet.encoding import PoissonEncoder\n",
        "from bindsnet.models import DiehlAndCook2015\n",
        "from bindsnet.network.monitors import Monitor\n",
        "from bindsnet.utils import get_square_weights, get_square_assignments\n",
        "from bindsnet.evaluation import all_activity, proportion_weighting, assign_labels\n",
        "from bindsnet.analysis.plotting import plot_input, plot_spikes, plot_weights, plot_assignments, plot_performance, plot_voltages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1PxGz1Gy2tg"
      },
      "source": [
        "Let's train a Spiking Neural Network on the train set of the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWE0f9LosO-P"
      },
      "source": [
        "# Let's assign some important variables: the parameters of the Spiking Neural Networks\n",
        "# Seed\n",
        "seed = 0\n",
        "\n",
        "# Number of Neurons \n",
        "n_neurons = 100\n",
        "\n",
        "# Number of Epochs\n",
        "n_epochs = 1\n",
        "\n",
        "# Number of Train Samples\n",
        "n_train = 60000\n",
        "\n",
        "# Number of Test Samples\n",
        "n_test = 10000\n",
        "\n",
        "# Number of Working Threads\n",
        "n_workers = -1\n",
        "\n",
        "# Excitatory Voltage\n",
        "exc = 22.5\n",
        "\n",
        "# Inhibitory Voltage\n",
        "inh = 120\n",
        "\n",
        "# Theta Parameter\n",
        "theta_plus = 0.05\n",
        "\n",
        "# Time for the Data Encoding using Poisson\n",
        "time = 250\n",
        "\n",
        "# Time Delta for the Data Encoding using Poisson\n",
        "dt = 1.0\n",
        "\n",
        "# Intensity for the Data Encoding using Poisson\n",
        "intensity = 128\n",
        "\n",
        "# Progress Prints Parameters\n",
        "progress_interval = 10\n",
        "\n",
        "# Update Interval Prints Parameters\n",
        "update_interval = 250\n",
        "\n",
        "# Variable to activate plots\n",
        "plot = True\n",
        "\n",
        "# Variable to allow access to the GPU\n",
        "gpu = True\n",
        "\n",
        "\n",
        "\n",
        "# Set up GPU(s)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if gpu and torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "else:\n",
        "    torch.manual_seed(seed)\n",
        "    device = \"cpu\"\n",
        "    if gpu:\n",
        "        gpu = False\n",
        "\n",
        "\n",
        "# Set up number of threads\n",
        "torch.set_num_threads(os.cpu_count() - 1)\n",
        "print(f\"Running on: {device}\")\n",
        "\n",
        "\n",
        "# Determines number of threads to use\n",
        "if n_workers == -1:\n",
        "    n_workers = gpu * 4 * torch.cuda.device_count()\n",
        "\n",
        "\n",
        "# For plot purposes\n",
        "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
        "\n",
        "\n",
        "# Start intensity for data encoding\n",
        "start_intensity = intensity\n",
        "\n",
        "\n",
        "# Build Spiking Neural Network\n",
        "network = DiehlAndCook2015(\n",
        "    n_inpt=784,\n",
        "    n_neurons=n_neurons,\n",
        "    exc=exc,\n",
        "    inh=inh,\n",
        "    dt=dt,\n",
        "    norm=78.4,\n",
        "    theta_plus=theta_plus,\n",
        "    inpt_shape=(1, 28, 28),\n",
        ")\n",
        "\n",
        "\n",
        "# Move Network to the GPU\n",
        "if gpu:\n",
        "    network.to(\"cuda\")\n",
        "\n",
        "\n",
        "# Load MNIST data\n",
        "train_dataset = MNIST(\n",
        "    PoissonEncoder(time=time, dt=dt),\n",
        "    None,\n",
        "    root=os.path.join(\"data\", \"MNIST\"),\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "# Record spikes during the simulation\n",
        "spike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)\n",
        "\n",
        "\n",
        "# Neuron assignments, spike proportions and fire rates\n",
        "n_classes = 10\n",
        "assignments = -torch.ones(n_neurons, device=device)\n",
        "proportions = torch.zeros((n_neurons, n_classes), device=device)\n",
        "rates = torch.zeros((n_neurons, n_classes), device=device)\n",
        "\n",
        "\n",
        "# Sequence of accuracy estimates\n",
        "accuracy = {\"all\": [], \"proportion\": []}\n",
        "\n",
        "\n",
        "# Voltage recording for excitatory and inhibitory layers and add them to the Network\n",
        "exc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=int(time / dt), device=device)\n",
        "inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=int(time / dt), device=device)\n",
        "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
        "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
        "\n",
        "\n",
        "# Set up monitors for spikes and voltages\n",
        "# Spikes\n",
        "spikes = {}\n",
        "for layer in set(network.layers):\n",
        "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=int(time / dt), device=device)\n",
        "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
        "\n",
        "# Voltages\n",
        "voltages = {}\n",
        "for layer in set(network.layers) - {\"X\"}:\n",
        "    voltages[layer] = Monitor(network.layers[layer], state_vars=[\"v\"], time=int(time / dt), device=device)\n",
        "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\n",
        "\n",
        "\n",
        "# Pre-assing starting variables\n",
        "inpt_ims, inpt_axes = None, None\n",
        "spike_ims, spike_axes = None, None\n",
        "weights_im = None\n",
        "assigns_im = None\n",
        "perf_ax = None\n",
        "voltage_axes, voltage_ims = None, None\n",
        "\n",
        "\n",
        "# Train the network\n",
        "print(\"\\nBegin training.\\n\")\n",
        "\n",
        "# Start time\n",
        "start = t()\n",
        "\n",
        "# Create an empty list for the label (the training is unsupervised)\n",
        "labels = []\n",
        "\n",
        "\n",
        "# Go through all epochs\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    if epoch % progress_interval == 0:\n",
        "        print(\"Progress: %d / %d (%.4f seconds)\" % (epoch, n_epochs, t() - start))\n",
        "        start = t()\n",
        "\n",
        "    # Create a dataloader to iterate and batch data\n",
        "    dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "    for step, batch in enumerate(tqdm(dataloader)):\n",
        "        if step > n_train:\n",
        "            break\n",
        "        \n",
        "        # Get next input sample.\n",
        "        inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
        "        if gpu:\n",
        "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "\n",
        "        if step % update_interval == 0 and step > 0:\n",
        "            # Convert the array of labels into a tensor\n",
        "            label_tensor = torch.tensor(labels, device=device)\n",
        "\n",
        "            # Get network predictions\n",
        "            all_activity_pred = all_activity(spikes=spike_record, assignments=assignments, n_labels=n_classes)\n",
        "            \n",
        "            # Get neuron proportions\n",
        "            proportion_pred = proportion_weighting(spikes=spike_record, assignments=assignments, proportions=proportions, n_labels=n_classes)\n",
        "\n",
        "            # Compute network accuracy according to available classification strategies\n",
        "            accuracy[\"all\"].append(100 * torch.sum(label_tensor.long() == all_activity_pred).item() / len(label_tensor))\n",
        "            accuracy[\"proportion\"].append(100 * torch.sum(label_tensor.long() == proportion_pred).item() / len(label_tensor))\n",
        "\n",
        "            # Status prints\n",
        "            print(\"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\" % (accuracy[\"all\"][-1], np.mean(accuracy[\"all\"]), np.max(accuracy[\"all\"])))\n",
        "            print(\"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f (best)\\n\"% (accuracy[\"proportion\"][-1], np.mean(accuracy[\"proportion\"]), np.max(accuracy[\"proportion\"])))\n",
        "\n",
        "\n",
        "            # Assign labels to excitatory layer neurons\n",
        "            assignments, proportions, rates = assign_labels(spikes=spike_record, labels=label_tensor, n_labels=n_classes, rates=rates)\n",
        "\n",
        "            # Append the labels assigned in this batch\n",
        "            labels = []\n",
        "\n",
        "\n",
        "            # Save network into a .pt file\n",
        "            network.save('network.pt')\n",
        "\n",
        "            # Save the neuron assignments into a .pickle file\n",
        "            with open('assignments.pickle', 'wb') as fp:\n",
        "                cPickle.dump(assignments.detach().cpu().numpy(), fp, -1)\n",
        "\n",
        "\n",
        "            # Save the neuron proportion into a .pickle file\n",
        "            with open('proportions.pickle', 'wb') as fp:\n",
        "                cPickle.dump(proportions.detach().cpu().numpy(), fp, -1)\n",
        "\n",
        "            print('Model, assignments and proportions saved!')\n",
        "\n",
        "\n",
        "        # Append the batch labels to this list\n",
        "        labels.append(batch[\"label\"])\n",
        "\n",
        "\n",
        "        # Run the network on the inputs\n",
        "        network.run(inputs=inputs, time=time, input_time_dim=1)\n",
        "\n",
        "\n",
        "        # Get voltage recording\n",
        "        exc_voltages = exc_voltage_monitor.get(\"v\")\n",
        "        inh_voltages = inh_voltage_monitor.get(\"v\")\n",
        "\n",
        "\n",
        "        # Add to spikes recording\n",
        "        spike_record[step % update_interval] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
        "\n",
        "\n",
        "        # Optionally plot various simulation information.\n",
        "        if plot:\n",
        "            image = batch[\"image\"].view(28, 28)\n",
        "            inpt = inputs[\"X\"].view(time, 784).sum(0).view(28, 28)\n",
        "            input_exc_weights = network.connections[(\"X\", \"Ae\")].w\n",
        "            square_weights = get_square_weights(input_exc_weights.view(784, n_neurons), n_sqrt, 28)\n",
        "            square_assignments = get_square_assignments(assignments, n_sqrt)\n",
        "            spikes_ = {layer: spikes[layer].get(\"s\") for layer in spikes}\n",
        "            voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
        "            inpt_axes, inpt_ims = plot_input(image, inpt, label=batch[\"label\"], axes=inpt_axes, ims=inpt_ims)\n",
        "            spike_ims, spike_axes = plot_spikes(spikes_, ims=spike_ims, axes=spike_axes)\n",
        "            weights_im = plot_weights(square_weights, im=weights_im)\n",
        "            assigns_im = plot_assignments(square_assignments, im=assigns_im)\n",
        "            perf_ax = plot_performance(accuracy, x_scale=update_interval, ax=perf_ax)\n",
        "            voltage_ims, voltage_axes = plot_voltages(voltages, ims=voltage_ims, axes=voltage_axes, plot_type=\"line\")\n",
        "\n",
        "            plt.pause(1e-8)\n",
        "\n",
        "\n",
        "        # Reset state variables.\n",
        "        network.reset_state_variables()  \n",
        "\n",
        "        print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
        "\n",
        "\n",
        "print(\"Training complete.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6MH6hMO4_r6"
      },
      "source": [
        "Let's evaluate the performance of our network on the test set of the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfgJYQoH5ONV"
      },
      "source": [
        "# Update this variable (for prints and plots purposes)\n",
        "update_interval = n_test\n",
        "\n",
        "\n",
        "# Build network again\n",
        "network = DiehlAndCook2015(n_inpt=784, n_neurons=n_neurons, exc=exc, inh=inh, dt=dt, norm=78.4, theta_plus=theta_plus, inpt_shape=(1, 28, 28))\n",
        "\n",
        "# Load network parameters\n",
        "network = torch.load('network.pt')\n",
        "\n",
        "# Move the network to the GPU\n",
        "if gpu:\n",
        "    network.to(\"cuda\")\n",
        "\n",
        "\n",
        "# Record spikes during the simulation\n",
        "spike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)\n",
        "\n",
        "\n",
        "# Load the neuron assignments and spike proportions (the network learned this during training)\n",
        "n_classes = 10\n",
        "\n",
        "# Assignments\n",
        "with open('assignments.pickle', \"rb\") as f:\n",
        "    assignments = cPickle.load(f)\n",
        "\n",
        "assignments = torch.from_numpy(assignments).to(device)\n",
        "\n",
        "# Proportions\n",
        "with open('proportions.pickle', \"rb\") as f:\n",
        "    proportions = cPickle.load(f)\n",
        "\n",
        "proportions = torch.from_numpy(proportions).to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Voltage recording for excitatory and inhibitory layers\n",
        "exc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=int(time / dt), device=device)\n",
        "inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=int(time / dt), device=device)\n",
        "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
        "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
        "\n",
        "# Set up monitors for spikes and voltages\n",
        "# Spikes\n",
        "spikes = {}\n",
        "for layer in set(network.layers):\n",
        "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=int(time / dt), device=device)\n",
        "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
        "\n",
        "# Voltages\n",
        "voltages = {}\n",
        "for layer in set(network.layers) - {\"X\"}:\n",
        "    voltages[layer] = Monitor(network.layers[layer], state_vars=[\"v\"], time=int(time / dt), device=device)\n",
        "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\n",
        "\n",
        "\n",
        "# Load MNIST test data\n",
        "test_dataset = MNIST(PoissonEncoder(time=time, dt=dt), None, root=os.path.join(\"data\", \"MNIST\"), download=True, train=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]))\n",
        "\n",
        "# Sequence of accuracy estimates.\n",
        "accuracy = {\"all\": 0, \"proportion\": 0}\n",
        "\n",
        "# Record spikes during the simulation\n",
        "spike_record = torch.zeros((1, int(time / dt), n_neurons), device=device)\n",
        "\n",
        "# Test the network\n",
        "print(\"\\nBegin testing\\n\")\n",
        "\n",
        "# Put the network in test mode\n",
        "network.train(mode=False)\n",
        "\n",
        "# Start time\n",
        "start = t()\n",
        "\n",
        "# Get a fancy TQDM progress bar\n",
        "pbar = tqdm(total=n_test)\n",
        "\n",
        "\n",
        "# Create a list with the labels\n",
        "r_labels = [i for i in range(n_classes)]\n",
        "\n",
        "# Run the network on the data\n",
        "for step, batch in enumerate(test_dataset):\n",
        "    if step > n_test:\n",
        "        break\n",
        "    \n",
        "    # Get next input sample.\n",
        "    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
        "    if gpu:\n",
        "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "    # Run the network on the input.\n",
        "    network.run(inputs=inputs, time=time, input_time_dim=1)\n",
        "\n",
        "    # Add to spikes recording.\n",
        "    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
        "\n",
        "    # Convert the array of labels into a tensor\n",
        "    label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
        "\n",
        "    # Get the label\n",
        "    label = batch[\"label\"]\n",
        "\n",
        "    # Get network predictions\n",
        "    all_activity_pred = all_activity(spikes=spike_record, assignments=assignments, n_labels=n_classes)\n",
        "    proportion_pred = proportion_weighting(spikes=spike_record, assignments=assignments, proportions=proportions, n_labels=n_classes)\n",
        "\n",
        "    # Compute network accuracy according to available classification strategies.\n",
        "    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
        "    accuracy[\"proportion\"] += float(torch.sum(label_tensor.long() == proportion_pred).item())\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / (step + 1)))\n",
        "        print(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / (step + 1)))\n",
        "\n",
        "\n",
        "    # Reset state variables.\n",
        "    network.reset_state_variables()  \n",
        "    pbar.set_description_str(\"Test progress: \")\n",
        "    pbar.update()\n",
        "\n",
        "print(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / n_test))\n",
        "print(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / n_test))\n",
        "\n",
        "print(\"Testing complete.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YzVPnq3HPmH"
      },
      "source": [
        "## Challenge: can you pick up one (or more) dataset(s) and build the entire pipeline yourself?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bSg2y9IHrFq"
      },
      "source": [
        "# Start your code here\n",
        "# Some hints for stuff you will have to import:\n",
        "# For Fashion-MNIST: from bindsnet.datasets import FashionMNIST\n",
        "# For CIFAR-10: from bindsnet.datasets import CIFAR10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onbNvrUQ8Z0P"
      },
      "source": [
        "# More tutorials, exercises and readings:\n",
        "\n",
        "\n",
        "1.   [BindsNET Documentation](https://bindsnet-docs.readthedocs.io)\n",
        "\n",
        "2.   [BindsNET Examples](https://github.com/BindsNET/bindsnet/tree/master/examples)"
      ]
    }
  ]
}