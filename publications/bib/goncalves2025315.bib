@incollection{goncalves2025315,
    title = {{Chapter 15 - Interpretable AI for medical image analysis: methods, evaluation, and clinical considerations}},
    editor = {Marco Lorenzi and Maria A. Zuluaga},
    booktitle = {{Trustworthy AI in Medical Imaging}},
    publisher = {{Academic Press}},
    pages = {315-346},
    year = {2025},
    series = {{The MICCAI Society book Series}},
    isbn = {978-0-443-23761-4},
    doi = {https://doi.org/10.1016/B978-0-44-323761-4.00027-4},
    url = {https://www.sciencedirect.com/science/article/pii/B9780443237614000274},
    author = {Tiago Gonçalves and Anna Hedström and Aurélie {Pahud de Mortanges} and Xiaoxiao Li and Henning Müller and Jaime S. Cardoso and Mauricio Reyes},
    keywords = {Clinical XAI, Interpretable AI, Evaluating XAI, Explainable AI, Medical image analysis},
    abstract = {In the healthcare context, artificial intelligence (AI) has the potential to power decision support systems and help health professionals in their clinical decisions. However, given its complexity, AI is usually seen as a black box that receives data and outputs a prediction. This behavior may jeopardize the adoption of this technology by the healthcare community, which values the existence of explanations to justify a clinical decision. Besides, the developers must have a strategy to assess and audit these systems to ensure their reproducibility and quality in production. The field of interpretable artificial intelligence emerged to study how these algorithms work and clarify their behavior. This chapter reviews several interpretability of AI algorithms for medical imaging, discussing their functioning, limitations, benefits, applications, and evaluation strategies. The chapter concludes with considerations that might contribute to bringing these methods closer to the daily routine of healthcare professionals.}
}